{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pranay6826/ai-story-gen/blob/main/story%20clean.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JAG7sJ1RScP",
    "outputId": "6d989785-efbb-4dfe-acb2-351aa46855c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers accelerate bitsandbytes gradio torch sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bxEkrmeSRafo"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446,
     "referenced_widgets": [
      "b61c29b0c61e4a538c230710b3ee9d13",
      "534c2d8a3a874a6c93b18c9dd5253879",
      "92737b3c88f34d2b85f3626c2d5f16b5",
      "1446dc00391a471f9eebfe7fbb9378a0",
      "51f4441b23da4c26be71620bd27f7f87",
      "bc9ba98688044ff9b17d57c0350b58a7",
      "c8ff7506c9cd45a9b8c696a81feae32c",
      "fd54f028dce1483281024120496b55d4",
      "7f4cd65e363a4187bc4638769343c93f",
      "a5fefb8486124faaa69955290309ed1b",
      "7876bab5df1f4fd69121b5ce85d5983e",
      "172d98f62c174f0b8e86167666cab603",
      "6b990c478b9a4a849575499bc3e1dba0",
      "9abe2d11a61743e2ba062c5323c44bc6",
      "17ff9868d7b64cf580a4365e20c50d06",
      "ce2ff95d5aff40f29915b12e7bf8dddc",
      "55e00773474c48a48e06c4e0b3ee475c",
      "1eae4942ed924302abe52c94c1e2ba8d",
      "199429cde61b4a4b9da4e7780e1ad106",
      "6f857c3c4a8e4895a12a100aa7db728d",
      "a85b7a8f653c43b8bf18dd8bb4f48e18",
      "92d1e022fc39427eab64b9b92bb8f4a9",
      "86e3aa1bc3a1434eb6b12a9cca62c448",
      "cfc2304478304c73bc3531236fffe077",
      "81fbaf64f9eb4a72a7d3a914984cf737",
      "211d5206b3e2457e987243f6953cc39a",
      "d27aacb8c0c9420dbdf222f0881b5876",
      "121627dd50474f9aa23646e43c1d8fee",
      "deaf594bf3844cf783b7c015fde87315",
      "3e42b2b75bc646ecb0ade62ace29c4b2",
      "8e61e1fd619c4ecf9a973c22c9645325",
      "869b023645484d79a44f46bc3cd7910c",
      "675d3741eedf437cad6f7c8d9b5dc248",
      "c129f31811a9447786fab3d8734e2467",
      "52dc8c1a79754dd2adea42170ab29f89",
      "e8bd0db224a04c16b47782b079e5fb37",
      "b3ce065cf0c64651b62ee17a4769f626",
      "d97033506ffd47e383035bd7dfa0817c",
      "2c902dc4f7c94c139cd65e49bdc728cc",
      "8fa5be043de4458e816e24a242dc6a92",
      "2cba8aad80914784a01406a8b01fa49a",
      "0559421d0a724cf2b276cdbdcad1d657",
      "e60541f8b2d9490ba9aa3553ba63dce7",
      "2b816265fc964c4183e2efe0863d7ad9",
      "b87b288ca21949f195e7f8b0cc4f2aaa",
      "da0990ab11314cdb96ab105787de397c",
      "a1a6fd1c0733451db943682e170cc6e0",
      "d12d657a96fe4a3287b63919c2b5efbe",
      "7f0fa0ff36ca4da899e9408d883781ad",
      "e09e27b75e664f62ad70c2256a1f3a59",
      "ec78e91033b44970b2d6dfab1e90a5e1",
      "855d5dc00f8141f391fef29ce4ae1ba5",
      "d221b774dbbc4a16bfd9bab9a155b24a",
      "414b7e44ec934bb4a2db2c8cd5ecdb7b",
      "ef7b3aa5f8b541c0b16ae547e6329089",
      "f2cf510189284cd18a645456e076d9ba",
      "29e9af7bb71242f79d790ff48693cf23",
      "f732fa376a70490e9f2aa7991b8498c8",
      "50320ad1135a4ade8fb3b92c938cd231",
      "ddc99b52efb2450e80ba337c85c1071f",
      "d2a9d300f03149738ebaeefb8d81a5a5",
      "88a5fe4e62de401f89e55e439e1812e1",
      "1bac73be644b47bcbb2b92a22f49059b",
      "458121c769db40d2811da7ce128cd7ad",
      "e77646bce61642f0b84c47f042675ea7",
      "42a41c7b364a4980bc09f3ff09ebff76",
      "cbee7405fd6d44adb75c5fb7154c9a77",
      "f5c60e1d159b4bc492b93e689deae9fa",
      "7311d9e229b34337bf1b3ad44dedcd82",
      "f19580e1507344a5a770652c8b5dd9c7",
      "735f2cc142a44879ad9fc6b96c581b98",
      "478a36366976420591a9a9181869e655",
      "7cf9c5d745b348968a702cc1f28c5179",
      "ee57c109df93459a9ae19e667cc13a10",
      "108e6e00b2b54255b962c730f6371fb8",
      "eec11bcbda5c40ccac59ace136c54359",
      "4ddd18191e7d40ffadb4ea0a0883058d",
      "1ff0f4861ae645d99a1f2c1f45631fef",
      "9fabd333ff584c6ab9eb2ab4e465b550",
      "f6885a29bccf4eed81b4a7a473a0d0f3",
      "a27cdc7fb5544e2ca4af14d9212fb5d7",
      "8995ec5c5cd845409e27f1dd55f7eaf3",
      "43969113ae834c1781b39ca612f243dd",
      "dcc0d4117e104bbe9ac1673b6f8bd035",
      "3be4b2ad9e4941158a4c4509c807fc38",
      "9b26505980a14d3cb93fa281cc2f05b6",
      "1539534de28a41dc8bc64db3c164bd7d",
      "6ddbd83cb7b64264839a9a09501d7937",
      "efa6633519f7481b99a95480cc527167",
      "45421617e9a9482f9c8b9d872147f8f2",
      "205d7be39ff446b1b38417f441ad993a",
      "3f181391822645c3b679b828ffcec95c",
      "f657041dad33464fa29b7331c0a5aec2",
      "4af37f05db5744899acfcaf4b6e0a022",
      "a1e12a763c6643019039c2ebaa8d1056",
      "e699c1949adf4374a8b687d353324488",
      "9f5a89c7d6c948b88a719d4d8bdcf338",
      "747c01ee6b55423c8b94168c7d69ed3f",
      "4b994a524cf44121bd7f3e053ee48578"
     ]
    },
    "id": "15IEqNgNRfCe",
    "outputId": "620f3b8c-9514-4a77-8e3d-db9ae8b96841"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61c29b0c61e4a538c230710b3ee9d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172d98f62c174f0b8e86167666cab603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e3aa1bc3a1434eb6b12a9cca62c448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c129f31811a9447786fab3d8734e2467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87b288ca21949f195e7f8b0cc4f2aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cf510189284cd18a645456e076d9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbee7405fd6d44adb75c5fb7154c9a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff0f4861ae645d99a1f2c1f45631fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa6633519f7481b99a95480cc527167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "sJe-SjdjRiro",
    "outputId": "58eee57b-7668-4566-8c6a-9725db79b0ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://219d1b4a2f2abfb731.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://219d1b4a2f2abfb731.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_story(prompt):\n",
    "    if not prompt.strip():\n",
    "        return \" Please enter a story prompt!\"\n",
    "\n",
    "    story_prompt = (\n",
    "        \"Write a creative short story based on the following prompt. \"\n",
    "        \"The story should include:\\n\"\n",
    "        \"- An engaging beginning\\n\"\n",
    "        \"- Interesting characters\\n\"\n",
    "        \"- A conflict or challenge\\n\"\n",
    "        \"- A satisfying resolution\\n\\n\"\n",
    "        f\"Prompt: {prompt}\\n\\nStory:\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        inputs = tokenizer(story_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(**inputs, max_new_tokens=500)\n",
    "        story = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        if \"Story:\" in story:\n",
    "            story = story.split(\"Story:\")[1].strip()\n",
    "        return story\n",
    "    except Exception as e:\n",
    "        return f\" Error: {str(e)}\"\n",
    "\n",
    "custom_css = \"\"\"\n",
    "body {\n",
    "    background: #fdfdfd;\n",
    "    font-family: 'Segoe UI', sans-serif;\n",
    "    color: #1f2937;\n",
    "}\n",
    "\n",
    ".gr-markdown h1 {\n",
    "    font-size: 36px;\n",
    "    color: #3b0764;\n",
    "    text-align: center;\n",
    "    margin-top: 20px;\n",
    "}\n",
    "\n",
    ".gr-textbox textarea {\n",
    "    font-size: 16px !important;\n",
    "    font-family: 'Georgia', serif !important;\n",
    "    border-radius: 12px !important;\n",
    "    background: #fff9f0 !important;\n",
    "    border: 2px solid #fde68a !important;\n",
    "    padding: 14px !important;\n",
    "    resize: vertical;\n",
    "}\n",
    "\n",
    ".gr-button {\n",
    "    background: linear-gradient(to right, #f59e0b, #eab308) !important;\n",
    "    color: #1f2937 !important;\n",
    "    font-weight: 600;\n",
    "    padding: 12px 24px;\n",
    "    font-size: 16px;\n",
    "    border-radius: 10px;\n",
    "    margin-top: 10px;\n",
    "}\n",
    "\n",
    ".gr-button:hover {\n",
    "    background: #facc15 !important;\n",
    "}\n",
    "\n",
    "#story-card {\n",
    "    background: #1e1e1e;\n",
    "    border-left: 6px solid #fbbf24;\n",
    "    padding: 20px;\n",
    "    margin-top: 20px;\n",
    "    font-size: 16px;\n",
    "    border-radius: 10px;\n",
    "    font-family: 'Georgia', serif;\n",
    "    box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n",
    "    color: #3f6212;\n",
    "    white-space: pre-wrap;\n",
    "}\n",
    "\n",
    "@media (max-width: 600px) {\n",
    "    .gr-textbox textarea, #story-card {\n",
    "        font-size: 15px !important;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with gr.Blocks(css=custom_css, theme=gr.themes.Base()) as demo:\n",
    "    gr.Markdown(\"# AI Story Generator\")\n",
    "\n",
    "    prompt_input = gr.Textbox(\n",
    "        label=\" Enter a creative story prompt:\",\n",
    "        placeholder=\"e.g., A dragon discovers an abandoned library in the mountains...\",\n",
    "        lines=4,\n",
    "    )\n",
    "\n",
    "    generate_btn = gr.Button(\" Tell me a story\")\n",
    "\n",
    "    story_output = gr.Textbox(\n",
    "        label=\" Your AI Story\",\n",
    "        interactive=False,\n",
    "        lines=20,\n",
    "        elem_id=\"story-card\",\n",
    "        show_copy_button=True\n",
    "    )\n",
    "\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"A girl finds a door behind her wardrobe that leads to another century\"],\n",
    "            [\"An alien becomes friends with a stray dog in New York\"],\n",
    "            [\"A village where people dream the same dream every night\"],\n",
    "        ],\n",
    "        inputs=prompt_input\n",
    "    )\n",
    "\n",
    "    generate_btn.click(fn=generate_story, inputs=prompt_input, outputs=story_output)\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
