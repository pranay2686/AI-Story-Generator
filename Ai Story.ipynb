{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56a9b67c78f49aa88901b6fb60a5fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01f7043c3874d529d2a9cea26f15cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635b518f618d47d4a0c5d9ed671ef827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79cbe626af345f89f67591635843383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434c54a3deea4f8a802de04c48cc4683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04d2b53a1174bc989888ea406891e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63db8db748d34cea81455a498492013c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47242d33d46f4dfa83a80dcc624e52d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79b465eef3342d6a5c25b9256f8e8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://eaadda54ce9c36d95a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://eaadda54ce9c36d95a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q transformers accelerate bitsandbytes gradio torch sentencepiece\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import gradio as gr\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "def generate_story(prompt):\n",
    "    if not prompt.strip():\n",
    "        return \" Please enter a story prompt!\"\n",
    "\n",
    "    story_prompt = (\n",
    "        \"Write a creative short story based on the following prompt. \"\n",
    "        \"The story should include:\\n\"\n",
    "        \"- An engaging beginning\\n\"\n",
    "        \"- Interesting characters\\n\"\n",
    "        \"- A conflict or challenge\\n\"\n",
    "        \"- A satisfying resolution\\n\\n\"\n",
    "        f\"Prompt: {prompt}\\n\\nStory:\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        inputs = tokenizer(story_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(**inputs, max_new_tokens=500)\n",
    "        story = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        if \"Story:\" in story:\n",
    "            story = story.split(\"Story:\")[1].strip()\n",
    "        return story\n",
    "    except Exception as e:\n",
    "        return f\" Error: {str(e)}\"\n",
    "\n",
    "custom_css = \"\"\"\n",
    "body {\n",
    "    background: #fdfdfd;\n",
    "    font-family: 'Segoe UI', sans-serif;\n",
    "    color: #1f2937;\n",
    "}\n",
    "\n",
    ".gr-markdown h1 {\n",
    "    font-size: 36px;\n",
    "    color: #3b0764;\n",
    "    text-align: center;\n",
    "    margin-top: 20px;\n",
    "}\n",
    "\n",
    ".gr-textbox textarea {\n",
    "    font-size: 16px !important;\n",
    "    font-family: 'Georgia', serif !important;\n",
    "    border-radius: 12px !important;\n",
    "    background: #fff9f0 !important;\n",
    "    border: 2px solid #fde68a !important;\n",
    "    padding: 14px !important;\n",
    "    resize: vertical;\n",
    "}\n",
    "\n",
    ".gr-button {\n",
    "    background: linear-gradient(to right, #f59e0b, #eab308) !important;\n",
    "    color: #1f2937 !important;\n",
    "    font-weight: 600;\n",
    "    padding: 12px 24px;\n",
    "    font-size: 16px;\n",
    "    border-radius: 10px;\n",
    "    margin-top: 10px;\n",
    "}\n",
    "\n",
    ".gr-button:hover {\n",
    "    background: #facc15 !important;\n",
    "}\n",
    "\n",
    "#story-card {\n",
    "    background: #1e1e1e;\n",
    "    border-left: 6px solid #fbbf24;\n",
    "    padding: 20px;\n",
    "    margin-top: 20px;\n",
    "    font-size: 16px;\n",
    "    border-radius: 10px;\n",
    "    font-family: 'Georgia', serif;\n",
    "    box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n",
    "    color: #3f6212;\n",
    "    white-space: pre-wrap;\n",
    "}\n",
    "\n",
    "@media (max-width: 600px) {\n",
    "    .gr-textbox textarea, #story-card {\n",
    "        font-size: 15px !important;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with gr.Blocks(css=custom_css, theme=gr.themes.Base()) as demo:\n",
    "    gr.Markdown(\"# AI Story Generator\")\n",
    "\n", gr.HTML("""
    <div style="text-align: center; margin: 10px 0 20px 0;">
        <a href="https://colab.research.google.com/github/YOUR_GITHUB_USERNAME/YOUR_REPO_NAME/blob/main/Ai_clean.ipynb" target="_blank">
            <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">
        </a>
    </div>
    """)
    "    prompt_input = gr.Textbox(\n",
    "        label=\" Enter a creative story prompt:\",\n",
    "        placeholder=\"e.g., A dragon discovers an abandoned library in the mountains...\",\n",
    "        lines=4,\n",
    "    )\n",
    "\n",
    "    generate_btn = gr.Button(\" Tell me a story\")\n",
    "\n",
    "    story_output = gr.Textbox(\n",
    "        label=\" Your AI Story\",\n",
    "        interactive=False,\n",
    "        lines=20,\n",
    "        elem_id=\"story-card\",\n",
    "        show_copy_button=True\n",
    "    )\n",
    "\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"A girl finds a door behind her wardrobe that leads to another century\"],\n",
    "            [\"An alien becomes friends with a stray dog in New York\"],\n",
    "            [\"A village where people dream the same dream every night\"],\n",
    "        ],\n",
    "        inputs=prompt_input\n",
    "    )\n",
    "\n",
    "    generate_btn.click(fn=generate_story, inputs=prompt_input, outputs=story_output)\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
